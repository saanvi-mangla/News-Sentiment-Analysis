# -*- coding: utf-8 -*-
"""sentiment_analyzer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oD6C5RVOUk2ljkMec2UK15YybJ1xzOs3
"""



# -*- coding: utf-8 -*-
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import config
import logging
import os

def load_sentiment_model_and_tokenizer():
    """Loads the fine-tuned sentiment model and tokenizer from disk."""
    model_path = config.FINAL_MODEL_DIR
    if not os.path.isdir(model_path):
        logging.error(f"Sentiment model directory not found at: {model_path}")
        print(f"Error: Model directory '{model_path}' not found. Please run the training script (4_fine_tune_model.py) first.")
        return None, None

    try:
        logging.info(f"Loading sentiment model from: {model_path}")
        model = AutoModelForSequenceClassification.from_pretrained(model_path).to(config.DEVICE)
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model.eval() # Set model to evaluation mode
        logging.info("Sentiment model and tokenizer loaded successfully.")
        return model, tokenizer
    except Exception as e:
        logging.error(f"Error loading model/tokenizer from '{model_path}': {e}", exc_info=True)
        return None, None

def predict_sentiment(text, model, tokenizer):
    """Predicts sentiment for a given text using the loaded model."""
    if model is None or tokenizer is None:
        return "Sentiment Model Not Loaded"

    logging.info(f"Predicting sentiment for: '{text[:50]}...'")
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512).to(config.DEVICE)
    with torch.no_grad():
        logits = model(**inputs).logits

    predicted_class_id = torch.argmax(logits, dim=1).item()
    return model.config.id2label[predicted_class_id]